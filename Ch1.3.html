<!DOCTYPE HTML>
<html lang="en" class="light sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>优化基础 - Robotic Embodied Intelligence - From Zero to Hero</title>


        <!-- Custom HTML head -->

        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon-de23e50b.svg">
        <link rel="shortcut icon" href="favicon-8114d1fc.png">
        <link rel="stylesheet" href="css/variables-8adf115d.css">
        <link rel="stylesheet" href="css/general-2459343d.css">
        <link rel="stylesheet" href="css/chrome-ae938929.css">
        <link rel="stylesheet" href="css/print-9e4910d8.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="fonts/fonts-9644e21d.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="mdbook-highlight-css" href="highlight-493f70e1.css">
        <link rel="stylesheet" id="mdbook-tomorrow-night-css" href="tomorrow-night-4c0ae647.css">
        <link rel="stylesheet" id="mdbook-ayu-highlight-css" href="ayu-highlight-3fdfc3ac.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="src/css/custom-a0f5ac24.css">

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "light";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex-9218460c.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc-a5a73760.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>←</kbd> or <kbd>→</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="mdbook-body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="mdbook-sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("mdbook-sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="mdbook-sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="mdbook-sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="mdbook-page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="mdbook-menu-bar-hover-placeholder"></div>
                <div id="mdbook-menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="mdbook-sidebar-toggle" class="icon-button" for="mdbook-sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="mdbook-sidebar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M0 96C0 78.3 14.3 64 32 64H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32C14.3 128 0 113.7 0 96zM0 256c0-17.7 14.3-32 32-32H416c17.7 0 32 14.3 32 32s-14.3 32-32 32H32c-17.7 0-32-14.3-32-32zM448 416c0 17.7-14.3 32-32 32H32c-17.7 0-32-14.3-32-32s14.3-32 32-32H416c17.7 0 32 14.3 32 32z"/></svg></span>
                        </label>
                        <button id="mdbook-theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="mdbook-theme-list">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M371.3 367.1c27.3-3.9 51.9-19.4 67.2-42.9L600.2 74.1c12.6-19.5 9.4-45.3-7.6-61.2S549.7-4.4 531.1 9.6L294.4 187.2c-24 18-38.2 46.1-38.4 76.1L371.3 367.1zm-19.6 25.4l-116-104.4C175.9 290.3 128 339.6 128 400c0 3.9 .2 7.8 .6 11.6c1.8 17.5-10.2 36.4-27.8 36.4H96c-17.7 0-32 14.3-32 32s14.3 32 32 32H240c61.9 0 112-50.1 112-112c0-2.5-.1-5-.2-7.5z"/></svg></span>
                        </button>
                        <ul id="mdbook-theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="mdbook-theme-ayu">Ayu</button></li>
                        </ul>
                        <button id="mdbook-search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="mdbook-searchbar">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M416 208c0 45.9-14.9 88.3-40 122.7L502.6 457.4c12.5 12.5 12.5 32.8 0 45.3s-32.8 12.5-45.3 0L330.7 376c-34.4 25.2-76.8 40-122.7 40C93.1 416 0 322.9 0 208S93.1 0 208 0S416 93.1 416 208zM208 352c79.5 0 144-64.5 144-144s-64.5-144-144-144S64 128.5 64 208s64.5 144 144 144z"/></svg></span>
                        </button>
                    </div>

                    <h1 class="menu-title">Robotic Embodied Intelligence - From Zero to Hero</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <span class=fa-svg id="print-button"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M128 0C92.7 0 64 28.7 64 64v96h64V64H354.7L384 93.3V160h64V93.3c0-17-6.7-33.3-18.7-45.3L400 18.7C388 6.7 371.7 0 354.7 0H128zM384 352v32 64H128V384 368 352H384zm64 32h32c17.7 0 32-14.3 32-32V256c0-35.3-28.7-64-64-64H64c-35.3 0-64 28.7-64 64v96c0 17.7 14.3 32 32 32H64v64c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V384zm-16-88c-13.3 0-24-10.7-24-24s10.7-24 24-24s24 10.7 24 24s-10.7 24-24 24z"/></svg></span>
                        </a>
                        <a href="https://Yang-Yang.me/" title="Git repository" aria-label="Git repository">
                            <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M272 304h-96C78.8 304 0 382.8 0 480c0 17.67 14.33 32 32 32h384c17.67 0 32-14.33 32-32C448 382.8 369.2 304 272 304zM48.99 464C56.89 400.9 110.8 352 176 352h96c65.16 0 119.1 48.95 127 112H48.99zM224 256c70.69 0 128-57.31 128-128c0-70.69-57.31-128-128-128S96 57.31 96 128C96 198.7 153.3 256 224 256zM224 48c44.11 0 80 35.89 80 80c0 44.11-35.89 80-80 80S144 172.1 144 128C144 83.89 179.9 48 224 48z"/></svg></span>
                        </a>

                    </div>
                </div>

                <div id="mdbook-search-wrapper" class="hidden">
                    <form id="mdbook-searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="mdbook-searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="mdbook-searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <span class=fa-svg id="fa-spin"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M304 48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zm0 416c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM48 304c26.5 0 48-21.5 48-48s-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48zm464-48c0-26.5-21.5-48-48-48s-48 21.5-48 48s21.5 48 48 48s48-21.5 48-48zM142.9 437c18.7-18.7 18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zm0-294.2c18.7-18.7 18.7-49.1 0-67.9S93.7 56.2 75 75s-18.7 49.1 0 67.9s49.1 18.7 67.9 0zM369.1 437c18.7 18.7 49.1 18.7 67.9 0s18.7-49.1 0-67.9s-49.1-18.7-67.9 0s-18.7 49.1 0 67.9z"/></svg></span>
                            </div>
                        </div>
                    </form>
                    <div id="mdbook-searchresults-outer" class="searchresults-outer hidden">
                        <div id="mdbook-searchresults-header" class="searchresults-header"></div>
                        <ul id="mdbook-searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('mdbook-sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('mdbook-sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#mdbook-sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="mdbook-content" class="content">
                    <main>
                        <p>下面是按照你给出的提纲，完整撰写的 <strong>1.3 优化基础</strong> 中几个小节内容草稿，风格偏教材化，适合研究生自学。从读者“会微积分和线性代数，但还没系统学过优化”的背景出发，尽量用通俗语言讲清楚核心概念，并在合适位置加了图片占位说明。公式部分保持到能看懂后面神经网络和 RL 论文为目标。</p>
<hr>
<h2 id="13-优化基础"><a class="header" href="#13-优化基础">1.3 优化基础</a></h2>
<p>在具身智能、深度学习和强化学习中，本质上都在做一件事：</p>
<blockquote>
<p><strong>找到一组参数，使某个“代价”或“损失”尽可能小。</strong></p>
</blockquote>
<p>这一节我们系统介绍优化的基本概念与方法，从最常见的梯度下降到约束优化、再到神经网络训练中的实际问题，为后续深度网络、RL、控制中的各种“求最优”打基础。</p>
<hr>
<h3 id="131-无约束优化与梯度下降"><a class="header" href="#131-无约束优化与梯度下降">1.3.1 无约束优化与梯度下降</a></h3>
<h4 id="1311-导数与梯度概念"><a class="header" href="#1311-导数与梯度概念">1.3.1.1 导数与梯度概念</a></h4>
<p><strong>（1）一元函数的导数：变化率的精确定义</strong></p>
<p>在高中数学里，导数通常被解释为切线斜率。更一般地，可以理解为：</p>
<blockquote>
<p>在一点附近，函数值对自变量的小变化有多敏感。</p>
</blockquote>
<p>设一元函数 (f(x))，在点 (x) 的导数定义为
$$
f’(x) = \lim_{h\to 0} \frac{f(x+h)-f(x)}{h}.
$$</p>
<ul>
<li>若 (f’(x) &gt; 0)：向右（(x) 增大）走一点，函数值会上升。</li>
<li>若 (f’(x) &lt; 0)：向右走一点，函数值会下降。</li>
<li>若 (f’(x) = 0)：在该点附近一阶上看不到“上升/下降”的趋势，这里可能是极大值、极小值或鞍点（后面会详细讲）。</li>
</ul>
<p><strong>（2）多元函数的偏导与梯度</strong></p>
<p>深度学习中的参数往往是高维向量 (\theta \in \mathbb{R}^d)，损失函数 (L(\theta)) 是多元函数。
对每个分量 (\theta_i) 的偏导数
$$
\frac{\partial L}{\partial \theta_i}
$$
衡量“只改变 (\theta_i)，保持其它分量不变”时，损失的变化率。</p>
<p>将所有偏导按分量收集起来，得到 <strong>梯度（gradient）</strong>：
$$
\nabla_\theta L(\theta) =
\begin{bmatrix}
\frac{\partial L}{\partial \theta_1}
\vdots
\frac{\partial L}{\partial \theta_d}
\end{bmatrix}.
$$</p>
<p>几何上，梯度有两个重要性质（在欧几里得度量下）：</p>
<ol>
<li><strong>方向</strong>：在当前点处，梯度指向函数“<strong>上升最快</strong>”的方向。</li>
<li><strong>负梯度方向</strong>：(-\nabla L) 是函数“<strong>下降最快</strong>”的方向。</li>
</ol>
<blockquote>
<p>【图 1.3-1 占位：二维函数的等高线图，标出某点处的梯度向量，显示梯度垂直等高线并指向上升最快方向；负梯度指向下降方向。】</p>
</blockquote>
<p>这两个性质是梯度下降法的核心依据。</p>
<hr>
<h4 id="1312-梯度下降法"><a class="header" href="#1312-梯度下降法">1.3.1.2 梯度下降法</a></h4>
<p><strong>（1）问题形式：无约束优化</strong></p>
<p>最简单也是最常见的优化问题形式是：</p>
<p>$$
\min_{\theta \in \mathbb{R}^d} L(\theta),
$$</p>
<p>没有额外等式/不等式约束（比如不要求 (\theta) 非负等），称为 <strong>无约束优化</strong>。在机器学习中，(\theta) 通常代表模型参数，(L(\theta)) 是在训练集上的损失或代价函数。(<a href="https://www.analyticsvidhya.com/blog/2020/10/how-does-the-gradient-descent-algorithm-work-in-machine-learning/?utm_source=chatgpt.com">Analytics Vidhya</a>)</p>
<p><strong>（2）梯度下降思想</strong></p>
<p>基于“负梯度是下降最快方向”这一事实，梯度下降（Gradient Descent）采用简单迭代：</p>
<p>$$
\theta^{(k+1)} = \theta^{(k)} - \eta \nabla_\theta L(\theta^{(k)}),
$$</p>
<p>其中：</p>
<ul>
<li>(k)：迭代步数；</li>
<li>(\eta &gt; 0)：步长或 <strong>学习率（learning rate）</strong>；</li>
<li>(\nabla_\theta L(\theta^{(k)}))：在当前参数的梯度。</li>
</ul>
<p>直观理解：</p>
<ul>
<li>每一步都“看一眼”当前坡度（梯度），</li>
<li>然后沿着下坡最快的方向走一小步（(-\eta \nabla L)），</li>
<li>希望最终走到“山谷底”（损失最小处）。(<a href="https://www.digitalocean.com/community/tutorials/intro-to-optimization-in-deep-learning-gradient-descent?utm_source=chatgpt.com">DigitalOcean</a>)</li>
</ul>
<blockquote>
<p>【图 1.3-2 占位：一维曲线 (L(\theta)) 图像，展示沿负导数方向移动的离散步点，逐步靠近最小值。】</p>
</blockquote>
<p><strong>（3）梯度下降的基本性质</strong></p>
<p>在一些理想条件下（比如 (L(\theta)) 是光滑且凸的），可以证明梯度下降会收敛到全局最小值，且步长足够小即可保证函数值单调下降。但在非凸问题（深度网络训练）中，梯度下降往往只能保证：</p>
<ul>
<li><strong>找到某个“还不错”的局部极小值或鞍点附近的低损失区域</strong>，
而不是严格意义上的全局最优。</li>
</ul>
<p>不过在深度学习的实际经验中，局部极小值问题远没有想象中那么可怕，重点反而在于收敛速度和训练稳定性，这些会在后面几小节展开。</p>
<hr>
<h4 id="1313-学习率对优化的影响"><a class="header" href="#1313-学习率对优化的影响">1.3.1.3 学习率对优化的影响</a></h4>
<p>学习率 (\eta) 决定每一步走多远，直接影响：</p>
<ul>
<li>收敛速度</li>
<li>是否发散</li>
<li>是否在最优附近震荡</li>
</ul>
<p><strong>（1）学习率过大：发散或震荡</strong></p>
<p>如果 (\eta) 取得非常大，一步走得太远，可能出现：</p>
<ul>
<li>每次更新都“跨过山谷”，在两侧来回跳，导致损失在最小值附近震荡；</li>
<li>甚至越走越远，损失越来越大，出现 <strong>发散</strong>。</li>
</ul>
<blockquote>
<p>【图 1.3-3 占位：一维损失曲线，分别画出合适步长、偏大步长（震荡）、极大步长（发散）的迭代轨迹对比。】</p>
</blockquote>
<p>在凸二次函数 (L(\theta) = \frac{1}{2}a\theta^2) 情况下，可以严格算出：
若 (\eta &gt; 2/a)，迭代就一定发散；(\eta\in(0,2/a)) 则可收敛。</p>
<p><strong>（2）学习率过小：收敛极慢</strong></p>
<p>若 (\eta) 非常小，梯度下降每次只迈出“蚂蚁步”，好处是几乎不会发散，坏处是：</p>
<ul>
<li>要走非常多步才能接近最优；</li>
<li>在实际深度网络训练中，会导致显存和时间成本都非常高。</li>
</ul>
<p><strong>（3）合适学习率：速度与稳定性的折中</strong></p>
<p>在深度学习实践中，一般：</p>
<ul>
<li>开始时使用相对较大的学习率加速下降；</li>
<li>后期逐渐减小学习率，在最优附近“慢慢收敛”，减少震荡。</li>
</ul>
<p>如何具体调度学习率，是 1.3.5 的重点内容之一。很多现代优化算法（如 Adam）本质上就是在智能地“调步长”——对不同参数维度、自不同时刻使用不同的有效学习率。(<a href="https://www.digitalocean.com/community/tutorials/intro-to-optimization-momentum-rmsprop-adam?utm_source=chatgpt.com">DigitalOcean</a>)</p>
<hr>
<h3 id="132-一阶与二阶优化方法直觉sgdmomentumadam-等"><a class="header" href="#132-一阶与二阶优化方法直觉sgdmomentumadam-等">1.3.2 一阶与二阶优化方法直觉（SGD、Momentum、Adam 等）</a></h3>
<p>在 1.3.1 中，梯度下降用到了目标函数的一阶导数（梯度）。更一般地，可以根据使用信息的多少，大致将优化方法分为：</p>
<ul>
<li><strong>一阶方法（first-order methods）</strong>：只依赖梯度；</li>
<li><strong>二阶方法（second-order methods）</strong>：还利用 Hessian（即二阶导信息）。</li>
</ul>
<p>从直觉上看：</p>
<ul>
<li>一阶方法：信息便宜、迭代快，但走路相对“笨拙”；</li>
<li>二阶方法：更聪明地利用“曲率”，但每一步计算非常贵，在大规模神经网络中通常不现实。</li>
</ul>
<hr>
<h4 id="1321-一阶方法"><a class="header" href="#1321-一阶方法">1.3.2.1 一阶方法</a></h4>
<p>一阶方法的共同特征：</p>
<blockquote>
<p>更新规则形如
(\theta^{(k+1)} = \theta^{(k)} + \text{某种函数}({\nabla L(\theta^{(t)})}_{t\le k}))。</p>
</blockquote>
<p><strong>（1）批量梯度下降（Batch GD）</strong></p>
<p>最原始的梯度下降在每一步都用 <strong>整批训练数据</strong> 计算损失和梯度，这在数据量巨大时计算代价非常高。深度学习实践中更常用的是 mini-batch 形式（见下面 SGD），这里略过。</p>
<p><strong>（2）随机梯度下降（Stochastic Gradient Descent, SGD）</strong></p>
<p>理论上需要在整批数据上计算梯度，但在实践中我们常用 <strong>一个样本或一个小批量样本</strong> 的梯度来近似整体梯度，这就是 <strong>随机梯度下降（SGD）</strong>：</p>
<p>$$
\theta^{(k+1)} = \theta^{(k)} - \eta \nabla_\theta \ell(x_{i_k}, y_{i_k}; \theta^{(k)}),
$$</p>
<p>其中：</p>
<ul>
<li>((x_{i_k}, y_{i_k})) 是在第 (k) 步随机抽取的样本或 mini-batch；</li>
<li>(\ell) 是单样本损失。</li>
</ul>
<p>这种“噪声较大的梯度”有两个好处：</p>
<ol>
<li><strong>更新更频繁，单步计算轻量</strong>，适合大数据场景；</li>
<li>由于带噪声，优化过程更容易“抖出”某些鞍点或坏的局部极小值，有助于探索更好的解。(<a href="https://wikidocs.net/166136?utm_source=chatgpt.com">wikidocs.net</a>)</li>
</ol>
<p><strong>（3）带动量的 SGD（Momentum）</strong></p>
<p>纯 SGD 更新路径常常是一条“抖动的折线”：在狭长谷底中来回摆动，收敛慢。<strong>动量（Momentum）</strong> 的思想是：</p>
<blockquote>
<p>不仅考虑当前梯度，还记住“过去一段时间的更新方向”，
就像物理中的惯性一样，让参数沿着过去累积的方向继续前进。(<a href="https://www.digitalocean.com/community/tutorials/intro-to-optimization-momentum-rmsprop-adam?utm_source=chatgpt.com">DigitalOcean</a>)</p>
</blockquote>
<p>典型形式（速度形式）：</p>
<p>$$
\begin{aligned}
v^{(k+1)} &amp;= \mu v^{(k)} - \eta \nabla_\theta L(\theta^{(k)}),
\theta^{(k+1)} &amp;= \theta^{(k)} + v^{(k+1)} ,
\end{aligned}
$$</p>
<p>其中：</p>
<ul>
<li>(v^{(k)})：“速度”或动量向量；</li>
<li>(\mu\in[0,1))：动量衰减系数（如 0.9）。</li>
</ul>
<p>直觉：</p>
<ul>
<li>在损失谷底的长轴方向上，梯度方向长期一致，动量会不断积累，使得沿谷底方向前进更快；</li>
<li>在与谷底垂直方向（损失变化陡峭的方向），梯度符号经常变化，动量会部分抵消震荡。</li>
</ul>
<p><strong>（4）自适应方法：RMSProp、Adam</strong></p>
<p>传统 SGD 对所有参数使用同一个学习率 (\eta)。但不同维度可能有不同尺度和重要性，自适应方法通过统计历史梯度大小，为不同参数自动调整“步长”。</p>
<p>以 <strong>Adam</strong> 为例（非常常见的优化器）：(<a href="https://www.digitalocean.com/community/tutorials/intro-to-optimization-momentum-rmsprop-adam?utm_source=chatgpt.com">DigitalOcean</a>)</p>
<ul>
<li>维护一阶矩（梯度的滑动平均） (m_t)；</li>
<li>维护二阶矩（梯度平方的滑动平均） (v_t)；</li>
<li>用这两个统计量对梯度进行“归一化”和“放缩”。</li>
</ul>
<p>简化后更新类似：
$$
\theta_{t+1} = \theta_t - \eta \cdot \frac{\hat m_t}{\sqrt{\hat v_t} + \epsilon}.
$$</p>
<p>直观上：</p>
<ul>
<li>(m_t) 类似动量，平滑梯度方向；</li>
<li>(\sqrt{v_t}) 则反映梯度幅度，对梯度长期较大的维度减小步长，对梯度较小的维度增大步长，实现自适应学习率。</li>
</ul>
<hr>
<h4 id="1322-二阶方法"><a class="header" href="#1322-二阶方法">1.3.2.2 二阶方法</a></h4>
<p>一阶方法只用梯度，而二阶方法还使用 <strong>Hessian 矩阵</strong>：</p>
<p>$$
H(\theta) = \nabla^2_\theta L(\theta),
$$
它是一个 (d\times d) 矩阵，每个元素是二阶偏导：
$$
H_{ij} = \frac{\partial^2 L}{\partial \theta_i \partial \theta_j}.
$$</p>
<p><strong>（1）曲率信息与“更聪明的步长”</strong></p>
<p>一元函数里，我们知道泰勒展开：
$$
L(\theta) \approx L(\theta_0) + L’(\theta_0)(\theta-\theta_0) + \frac{1}{2}L’’(\theta_0)(\theta-\theta_0)^2.
$$</p>
<p>若在附近用这个二次近似代替原函数，最小值的解析解是：
$$
\theta^\star \approx \theta_0 - \frac{L’(\theta_0)}{L’’(\theta_0)}.
$$</p>
<p>把这个推广到多元情形，就得到 <strong>牛顿法（Newton’s method）</strong> 的迭代：</p>
<p>$$
\theta^{(k+1)} = \theta^{(k)} - H(\theta^{(k)})^{-1} \nabla L(\theta^{(k)}).
$$</p>
<p>相比梯度下降 (-\eta\nabla L)，牛顿法将梯度再乘以 (H^{-1})，等价于在不同方向上动态调整步长，使得：</p>
<ul>
<li>在“弯曲得很厉害”（曲率大）的方向上，步子变小（防止跳太远）；</li>
<li>在“曲率较平缓”的方向上，步子变大，加速收敛。</li>
</ul>
<p><strong>（2）二阶方法的难点</strong></p>
<p>对于深度网络：</p>
<ul>
<li>参数维度 (d) 往往在百万甚至亿级，Hessian 是 (d\times d) 矩阵，
存储和求逆都是天文级成本；</li>
<li>计算 Hessian 本身也极其昂贵，且数值上不稳定。</li>
</ul>
<p>因此直接使用“严格的二阶方法”在深度网络中几乎不可行。</p>
<p><strong>（3）拟牛顿方法（简略了解）</strong></p>
<p>实际中有一些折中方案，如 BFGS、L-BFGS 等 <strong>拟牛顿法</strong>，通过在迭代中近似构造 (H^{-1})，而不显式求出完整 Hessian。这些方法在中等规模问题（如传统机器学习、小型网络）中依然常用，但在大规模深度学习里不再主流。</p>
<hr>
<h4 id="1323-实用考虑"><a class="header" href="#1323-实用考虑">1.3.2.3 实用考虑</a></h4>
<p>在深度学习和具身智能的实际训练里，通常采用：</p>
<ul>
<li><strong>一阶优化器为主</strong>（SGD / SGD+Momentum / Adam / RMSProp 等）；(<a href="https://www.digitalocean.com/community/tutorials/intro-to-optimization-momentum-rmsprop-adam?utm_source=chatgpt.com">DigitalOcean</a>)</li>
<li>在少数规模较小、需要高精度的模块中尝试二阶或拟牛顿方法。</li>
</ul>
<p>主要原因：</p>
<ol>
<li>模型参数维度太高，无法承担 Hessian 级别的计算和内存；</li>
<li>大量实践表明，<strong>好的初始化 + 合理的一阶优化 + 学习率调度</strong>，已足够得到很好的结果。</li>
</ol>
<p>在机器人和 VLA 模型中，优化器的选择往往是工程问题：</p>
<ul>
<li>需要更稳定、自动调节学习率：Adam / AdamW 常见；</li>
<li>更在意最终泛化性能、训练后期表现：不少视觉任务仍偏爱带动量的 SGD。</li>
</ul>
<hr>
<h3 id="133-损失景观与局部极值鞍点现象"><a class="header" href="#133-损失景观与局部极值鞍点现象">1.3.3 损失景观与局部极值、鞍点现象</a></h3>
<h4 id="1331-损失函数景观"><a class="header" href="#1331-损失函数景观">1.3.3.1 损失函数景观</a></h4>
<p><strong>损失景观（loss landscape）</strong> 是指：
在高维参数空间中，损失函数 (L(\theta)) 的取值构成的“山地地形”。</p>
<ul>
<li>每个点 (\theta) 是一组参数；</li>
<li>其对应高度 (L(\theta)) 是训练损失；</li>
<li>优化过程就是在这片高维山地上“下山”。</li>
</ul>
<blockquote>
<p>【图 1.3-4 占位：二维参数空间的损失等高线/三维曲面示意，标出多个谷地、鞍点和平坦区域。】</p>
</blockquote>
<p>在深度网络中，损失景观具有以下特点：(<a href="https://lcnwww.epfl.ch/gerstner/PUBLICATIONS/07Lecture07slidesForVideo.pdf?utm_source=chatgpt.com">lcnwww.epfl.ch</a>)</p>
<ul>
<li>高维（成千上万甚至更多参数）；</li>
<li>强烈非凸（有大量局部极值和鞍点）；</li>
<li>经常存在大面积的“平坦区”（梯度很小）和“陡峭沟壑”。</li>
</ul>
<p>理解损失景观有助于从几何视角解释：</p>
<ul>
<li>为什么梯度下降会卡住或变慢；</li>
<li>为什么初始化会影响最终结果；</li>
<li>为什么带噪声的 SGD 在实践中表现不错。</li>
</ul>
<hr>
<h4 id="1332-局部极小值与鞍点"><a class="header" href="#1332-局部极小值与鞍点">1.3.3.2 局部极小值与鞍点</a></h4>
<p><strong>（1）临界点（critical point）</strong></p>
<p>若在某点 (\theta^\star) 处梯度为零：
$$
\nabla L(\theta^\star) = 0,
$$
则称该点为 <strong>临界点</strong>。临界点可能是：</p>
<ul>
<li>局部极小值（local minimum）</li>
<li>局部极大值（local maximum）</li>
<li>鞍点（saddle point）</li>
</ul>
<p><strong>（2）局部极小值</strong></p>
<p>若存在足够小的邻域，使得：
$$
\forall \theta \text{ 在邻域内},\quad L(\theta) \ge L(\theta^\star),
$$
则 (\theta^\star) 是局部极小值。简单理解：
在附近任何方向稍微走一步，损失都会变大。</p>
<p>在凸优化中，每个局部极小值同时是全局极小值，世界清爽又温柔。可惜深度网络损失往往不是凸的。</p>
<p><strong>（3）鞍点（Saddle Point）</strong></p>
<p>鞍点是这样一种临界点：梯度为零，但在某些方向上表现得像极小值，在另一些方向上则像极大值——类似马鞍的形状：横向是谷，纵向是峰。(<a href="https://data-intelligence.hashnode.dev/saddle-points-machine-learning-deep-learning-optimization?utm_source=chatgpt.com">data-intelligence.hashnode.dev</a>)</p>
<ul>
<li>数学上：Hessian 的特征值有正有负；</li>
<li>几何上：既存在“向下的方向”，也存在“向上的方向”。</li>
</ul>
<p>在高维非凸优化中，研究与数值实验表明：</p>
<ul>
<li><strong>鞍点远比“坏的局部极小值”更多</strong>；</li>
<li>很多“训练卡住”的现象，实则是停在鞍点附近或平坦区域，而非真正的局部最小谷底。(<a href="https://lcnwww.epfl.ch/gerstner/PUBLICATIONS/07Lecture07slidesForVideo.pdf?utm_source=chatgpt.com">lcnwww.epfl.ch</a>)</li>
</ul>
<p><strong>（4）鞍点对优化的影响</strong></p>
<p>在鞍点附近，梯度接近零，普通梯度下降会：</p>
<ul>
<li>更新步长很小，移动缓慢；</li>
<li>可能长时间在附近徘徊，看起来像“训练不动了”。</li>
</ul>
<p>带噪声的 SGD 由于每步梯度有随机性，在一定程度上可以“抖出”鞍点，这也是实践中几乎总是使用 mini-batch 而不是纯 Batch GD 的原因之一。(<a href="https://apxml.com/courses/introduction-to-deep-learning/chapter-3-training-loss-optimization/gradient-descent-challenges?utm_source=chatgpt.com">ApX Machine Learning</a>)</p>
<hr>
<h4 id="1333-深度网络的损失特点"><a class="header" href="#1333-深度网络的损失特点">1.3.3.3 深度网络的损失特点</a></h4>
<p>近年来不少工作分析了深度网络的损失景观，一些典型结论包括：(<a href="https://jmlr.org/papers/volume25/23-0493/23-0493.pdf?utm_source=chatgpt.com">机器学习研究期刊</a>)</p>
<ol>
<li><strong>坏的局部极小值在高维情况下不一定很多。</strong>
在很多设置下，深度线性网络甚至可以证明不存在“劣质局部极小值”，只有全局极小和鞍点。</li>
<li><strong>鞍点和平坦区域是主要障碍。</strong>
训练变慢或停滞往往源于梯度接近零的平原或鞍点，而不是被困在某个特别高的局部谷底。</li>
<li><strong>“好极小值”往往成片存在</strong>（flat minima）。
一些较“平坦”的极小值（改变参数一点点损失不变太多）与泛化性能有一定关联——通常认为平坦极小值对应更好的泛化。</li>
</ol>
<p>对具身智能的实际意义：</p>
<ul>
<li>训练 VLA 或控制策略时，如果损失长时间不下降，未必是“模型不够强”，也可能是优化在不利的几何结构中爬得太慢；</li>
<li>调整优化器（如从 Adam 换成 SGD+Momentum），修改学习率调度、增加噪声等，常常可以改变在损失景观中的“走路方式”，找到更好的解。</li>
</ul>
<hr>
<h3 id="134-约束优化与拉格朗日乘子基本思想"><a class="header" href="#134-约束优化与拉格朗日乘子基本思想">1.3.4 约束优化与拉格朗日乘子基本思想</a></h3>
<p>前面讨论的是 <strong>无约束优化</strong>，但在机器人和具身智能里，很多问题天然带有约束，例如：</p>
<ul>
<li>关节角必须在物理范围内；</li>
<li>控制输入不能超过最大电机扭矩；</li>
<li>概率分布的参数必须非负且和为 1；</li>
<li>路径规划中必须避开障碍物等。</li>
</ul>
<p>这类问题统称为 <strong>约束优化（constrained optimization）</strong>。</p>
<hr>
<h4 id="1341-约束优化"><a class="header" href="#1341-约束优化">1.3.4.1 约束优化</a></h4>
<p>一般形式可以写作：</p>
<p>$$
\begin{aligned}
\min_{x} \quad &amp; f(x)
\text{s.t.} \quad &amp; g_i(x) = 0,\quad i=1,\dots,m \quad \text{（等式约束）}
&amp; h_j(x) \le 0,\quad j=1,\dots,p \quad \text{（不等式约束）}
\end{aligned}
$$</p>
<p>其中：</p>
<ul>
<li>(x\in \mathbb{R}^d)：待求参数（比如控制变量、概率参数等）；</li>
<li>(f(x))：目标函数（损失或代价）；</li>
<li>(g_i(x))、(h_j(x))：约束条件。</li>
</ul>
<p>机器人中的若干例子：</p>
<ul>
<li>机械臂逆运动学求解时要求末端达到给定位置（等式约束）；</li>
<li>控制优化中限制关节速度或力矩不超过上限（不等式约束）；</li>
<li>最大熵模型或概率分布学习中要求 (\sum_i p_i = 1, p_i \ge 0)。</li>
</ul>
<hr>
<h4 id="1342-拉格朗日乘子"><a class="header" href="#1342-拉格朗日乘子">1.3.4.2 拉格朗日乘子</a></h4>
<p><strong>（1）等式约束：拉格朗日乘子法</strong></p>
<p>考虑只有等式约束的情形：</p>
<p>$$
\begin{aligned}
\min_x \quad &amp; f(x)
\text{s.t.}\quad &amp; g_i(x) = 0,\quad i=1,\dots,m.
\end{aligned}
$$</p>
<p><strong>拉格朗日乘子法</strong> 的关键思想是：</p>
<blockquote>
<p>把“在约束面上找极值”的问题，转化为“在更高维空间中找无约束极值”的问题。(<a href="https://www.cs.toronto.edu/~mbrubake/teaching/C11/Handouts/LagrangeMultipliers.pdf?utm_source=chatgpt.com">cs.toronto.edu</a>)</p>
</blockquote>
<p>构造 <strong>拉格朗日函数：</strong></p>
<p>$$
\mathcal{L}(x, \lambda) = f(x) + \sum_{i=1}^m \lambda_i g_i(x),
$$</p>
<p>其中 (\lambda_i) 称为 <strong>拉格朗日乘子</strong>。此时的最优性条件（在一些技术条件下）可以写成：</p>
<p>$$
\nabla_x \mathcal{L}(x^\star,\lambda^\star) = 0,\quad g_i(x^\star)=0.
$$</p>
<p>直观意义：</p>
<ul>
<li>在最优点上，目标函数 (f(x)) 的梯度在约束面切平面内不能再下降；</li>
<li>拉格朗日乘子 (\lambda_i) 可以理解为“满足约束对目标值的边际代价”，在许多物理和经济问题中有很直观的解释。</li>
</ul>
<blockquote>
<p>【图 1.3-5 占位：二维函数等高线 + 一条曲线约束 (g(x)=0)（例如椭圆），示意在最优点处水平集与约束曲线切触，梯度方向与约束的梯度共线。】</p>
</blockquote>
<p><strong>（2）从优化到“方程组”</strong></p>
<p>使用拉格朗日乘子或 KKT 条件，本质上就是把“优化问题”转换为一组方程/不等式系统：
$$
\begin{cases}
\nabla_x \mathcal{L}(x,\lambda,\mu) = 0
g_i(x)=0
h_j(x)\le 0, \dots
\end{cases}
$$
这类系统在理论分析和某些算法（如内点法）中更容易处理。(<a href="https://math.stackexchange.com/questions/381840/lagrange-multipliers-and-kkt-conditions-what-do-we-gain?utm_source=chatgpt.com">Mathematics Stack Exchange</a>)</p>
<hr>
<h4 id="1343-kkt-条件"><a class="header" href="#1343-kkt-条件">1.3.4.3 KKT 条件</a></h4>
<p>当存在不等式约束时，拉格朗日乘子法需要推广到 <strong>Karush–Kuhn–Tucker（KKT）条件</strong>。它是非线性规划中非常重要的一阶必要条件。(<a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions?utm_source=chatgpt.com">维基百科</a>)</p>
<p>考虑一般问题：</p>
<p>$$
\begin{aligned}
\min_x \quad &amp; f(x)
\text{s.t.} \quad &amp; g_i(x) = 0,\quad i=1,\dots,m
&amp; h_j(x) \le 0,\quad j=1,\dots,p.
\end{aligned}
$$</p>
<p>构造 <strong>拉格朗日函数</strong>：
$$
\mathcal{L}(x,\lambda,\mu) = f(x) + \sum_{i=1}^m \lambda_i g_i(x) + \sum_{j=1}^p \mu_j h_j(x),
$$
其中：</p>
<ul>
<li>(\lambda_i)：等式约束的乘子；</li>
<li>(\mu_j)：不等式约束的乘子。</li>
</ul>
<p><strong>KKT 条件</strong> 包括：</p>
<ol>
<li><strong>原始可行性（primal feasibility）</strong>
满足原始约束：
$$
g_i(x^\star)=0,\quad h_j(x^\star)\le 0.
$$</li>
<li><strong>对偶可行性（dual feasibility）</strong>
不等式乘子非负：
$$
\mu_j^\star \ge 0.
$$</li>
<li><strong>站立条件（stationarity）</strong>
$$
\nabla_x \mathcal{L}(x^\star,\lambda^\star,\mu^\star) = 0.
$$</li>
<li><strong>互补松弛（complementary slackness）</strong>
$$
\mu_j^\star h_j(x^\star) = 0,\quad \forall j.
$$
这表示：
<ul>
<li>若某个不等式约束严格不等（(h_j(x^\star) &lt; 0)），则对应乘子必须为 0；</li>
<li>若乘子 (\mu_j^\star&gt;0)，则该约束一定正好“紧到边上”（(h_j(x^\star)=0)）。</li>
</ul>
</li>
</ol>
<p>在凸优化问题且满足一定正则条件时，KKT 条件不仅是必要条件，也是充分条件——即<strong>解满足 KKT 条件就一定是全局最优解</strong>。这为许多机器学习模型（如支持向量机）的推导提供了理论基础。</p>
<p>后面讲到最大间隔分类、软间隔 SVM 时，会再次用到这些工具。</p>
<hr>
<h3 id="135-神经网络训练中的优化实践问题学习率收敛与稳定性"><a class="header" href="#135-神经网络训练中的优化实践问题学习率收敛与稳定性">1.3.5 神经网络训练中的优化实践问题（学习率、收敛与稳定性）</a></h3>
<p>从这一小节开始，重点从“理论优化”切换到“神经网络训练实践”。在具身智能中，无论训练 VLM、VLA 还是 RL policy，都要面对如下问题：</p>
<ul>
<li>学习率如何设定与调度？</li>
<li>梯度为什么会消失或爆炸？</li>
<li>训练过程算不算收敛？什么时候终止？如何保持稳定？</li>
</ul>
<hr>
<h4 id="1351-学习率调度"><a class="header" href="#1351-学习率调度">1.3.5.1 学习率调度</a></h4>
<p>在 1.3.1.3 中，我们已经看到学习率大小对收敛速度和稳定性的影响。进一步地，<strong>学习率调度（learning rate schedule）</strong> 指的是在训练过程中随时间改变学习率的策略。</p>
<p><strong>（1）为什么要调度？</strong></p>
<ul>
<li>训练初期：需要较大的学习率快速“粗略找到好区域”；</li>
<li>训练后期：需要较小的学习率在最优附近细致调整，避免震荡；</li>
<li>某些模型训练需要“预热”（warm-up），防止一开始梯度太大导致发散。</li>
</ul>
<p><strong>（2）常见调度策略</strong></p>
<ol>
<li><strong>Step Decay</strong>：每过固定若干 epoch，将学习率乘以一个小于 1 的因子（例如每 30 个 epoch 乘以 0.1）。</li>
<li><strong>Exponential Decay</strong>：按 (\eta_t = \eta_0 \cdot \gamma^t) 指数衰减。</li>
<li><strong>Cosine Annealing（余弦退火）</strong>：学习率随训练进度在一个余弦曲线上缓慢减小，有时结合周期性重启使用。</li>
<li><strong>Warm-up + Scheduler</strong>：在前几百/几千步从非常小的值线性升高到目标学习率，然后按上述某种策略减小。</li>
</ol>
<p>实践经验（特别是在 Transformer 和大规模模型训练中）表明，合理的学习率调度往往比“纯粹换更复杂的优化器”带来的收益更稳定且可控。(<a href="https://www.digitalocean.com/community/tutorials/intro-to-optimization-momentum-rmsprop-adam?utm_source=chatgpt.com">DigitalOcean</a>)</p>
<hr>
<h4 id="1352-梯度消失与爆炸"><a class="header" href="#1352-梯度消失与爆炸">1.3.5.2 梯度消失与爆炸</a></h4>
<p><strong>（1）问题现象</strong></p>
<p>在深层网络中，反向传播时梯度会通过链式法则逐层相乘，如果每层的导数绝对值多数小于 1，则梯度会指数级减小，最终前面层几乎得不到更新，这就是 <strong>梯度消失（vanishing gradients）</strong>。(<a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem?utm_source=chatgpt.com">维基百科</a>)</p>
<p>反过来，如果导数绝对值多为大于 1，则梯度会指数级放大，导致 <strong>梯度爆炸（exploding gradients）</strong>：</p>
<ul>
<li>参数更新剧烈震荡甚至变成 NaN；</li>
<li>loss 突然变得非常大。</li>
</ul>
<p>这些问题在 RNN、非常深的前馈网络以及不合理初始化时尤其严重。(<a href="https://arxiv.org/html/2405.21064v1?utm_source=chatgpt.com">arXiv</a>)</p>
<p><strong>（2）成因直观</strong></p>
<p>简单看一维链式法则：
$$
\frac{\partial L}{\partial x_0} = \frac{\partial L}{\partial x_1} \frac{\partial x_1}{\partial x_0} = \frac{\partial L}{\partial x_n} \prod_{k=0}^{n-1} \frac{\partial x_{k+1}}{\partial x_k}.
$$</p>
<p>若每个 (\big|\frac{\partial x_{k+1}}{\partial x_k}\big|) 大约为 0.5，10 层后得到 (0.5^{10}\approx 1/1024)，梯度几乎消失；若每层约为 2，则 (2^{10}\approx 1024)，梯度爆炸。</p>
<p>在多层线性/非线性组合中，这种现象极易出现。</p>
<p><strong>（3）缓解方法</strong></p>
<p>常见手段包括：(<a href="https://en.wikipedia.org/wiki/Vanishing_gradient_problem?utm_source=chatgpt.com">维基百科</a>)</p>
<ol>
<li><strong>合理的权重初始化</strong>
<ul>
<li>Xavier 初始化：保证前向/反向信号方差在层间大致保持一致，适合 tanh 等。</li>
<li>Kaiming 初始化：针对 ReLU 族激活，考虑其非对称性。</li>
</ul>
</li>
<li><strong>合适的激活函数</strong>
<ul>
<li>用 ReLU、GELU 等替代 Sigmoid/Tanh，可以减轻梯度饱和问题。</li>
</ul>
</li>
<li><strong>归一化层</strong>
<ul>
<li>Batch Normalization、LayerNorm 等在前向上稳定中间层分布，也有助于避免梯度过大或过小。</li>
</ul>
</li>
<li><strong>残差连接（Residual Connections）</strong>
<ul>
<li>在 ResNet、Transformer 中广泛使用，允许梯度沿“捷径”反向传播，大幅缓解梯度消失问题。</li>
</ul>
</li>
<li><strong>梯度裁剪（Gradient Clipping）</strong>
<ul>
<li>对梯度的范数设置上限，例如若 (|g|_2 &gt; c) 则缩放为 (\frac{c}{|g|_2}g)，常用于 RNN 和强化学习策略网络中，防止爆炸。(<a href="https://datascience.stackexchange.com/questions/72351/how-to-prevent-vanishing-gradient-or-exploding-gradient?utm_source=chatgpt.com">Data Science Stack Exchange</a>)</li>
</ul>
</li>
</ol>
<p>在具身智能相关网络（例如 RNN/Transformer 控制策略、多帧视觉编码器）中，梯度消失与爆炸会直接导致策略不学或训练不稳定，是工程调参中的常见“坑”。</p>
<hr>
<h4 id="1353-收敛判断与稳定训练"><a class="header" href="#1353-收敛判断与稳定训练">1.3.5.3 收敛判断与稳定训练</a></h4>
<p><strong>（1）什么叫“收敛”？</strong></p>
<p>在理论上，收敛可以是：</p>
<ul>
<li>参数 (\theta^{(k)}) 收敛；</li>
<li>梯度 (\nabla L(\theta^{(k)}) \to 0)；</li>
<li>损失 (L(\theta^{(k)})) 收敛到某个值。</li>
</ul>
<p>在深度学习实践中，我们更关心：</p>
<ul>
<li>训练集损失是否持续下降并趋于平稳；</li>
<li>验证集性能是否达到平台期甚至开始下降（过拟合）。</li>
</ul>
<p><strong>（2）训练监控</strong></p>
<p>通常会绘制如下曲线：</p>
<ul>
<li>训练 loss vs. iteration / epoch；</li>
<li>验证 loss / 准确率 vs. epoch。</li>
</ul>
<p>在“健康”的训练过程中，一般会看到：</p>
<ul>
<li>前期训练 loss 快速下降；</li>
<li>中后期下降变缓，接近收敛；</li>
<li>若模型开始过拟合，训练集指标继续变好而验证集变差。</li>
</ul>
<p><strong>（3）稳定训练的常用技巧</strong></p>
<ol>
<li><strong>早停（Early Stopping）</strong>
在验证集性能长时间未提升甚至下降时，停止训练并回退到最佳验证点对应的参数，防止过拟合。</li>
<li><strong>检查学习率与梯度范围</strong>
若 loss 突然爆炸或梯度出现 NaN，优先怀疑学习率是否过大、是否缺少梯度裁剪或数值稳定处理。</li>
<li><strong>使用验证集而非训练 loss 判断收敛</strong>
对具身智能任务尤其重要，因为在真实机器人上往往只关心“在新场景、新物体上的成功率”，不能只看训练轨迹上的表现。</li>
<li><strong>多次重复实验与随机种子控制</strong>
优化过程本身带有随机性（初始化、mini-batch 抽样等），稳定结果应当在不同随机种子下大致一致，防止“偶然跑出一次好结果”。</li>
</ol>
<p>在后续章节（例如 2.2 深度网络训练技巧、9.4 数据工程与 MLOps）中，会进一步结合实验工程细节讨论如何系统监控和管理训练过程。</p>
<hr>
<p>这一节从导数和梯度开始，依次介绍了梯度下降、一阶/二阶方法直觉、损失景观与鞍点、约束优化与拉格朗日/KKT，再到神经网络训练中的学习率、梯度消失/爆炸以及收敛判断。掌握这些内容后，读者应该能：</p>
<ul>
<li>看懂大多数深度学习论文中涉及优化的公式；</li>
<li>理解主流优化器（SGD、Momentum、Adam 等）的核心思想；</li>
<li>在训练自己的网络（包括具身智能中的 VLA 模型）时，有一套清晰的调参和诊断思路。</li>
</ul>
<p>后续章节将在此基础上，进一步讨论深度网络结构、Transformer、RL 与模仿学习中的优化问题，逐步搭建起完整的“从感知到控制”的学习图景。</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="Ch1.2.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                            </a>

                            <a rel="next prefetch" href="Ch1.4.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="Ch1.2.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M41.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"/></svg></span>
                    </a>

                    <a rel="next prefetch" href="Ch1.4.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M278.6 233.4c12.5 12.5 12.5 32.8 0 45.3l-160 160c-12.5 12.5-32.8 12.5-45.3 0s-12.5-32.8 0-45.3L210.7 256 73.4 118.6c-12.5-12.5-12.5-32.8 0-45.3s32.8-12.5 45.3 0l160 160z"/></svg></span>
                    </a>
            </nav>

        </div>

        <template id=fa-eye><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg></span></template>
        <template id=fa-eye-slash><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 640 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M38.8 5.1C28.4-3.1 13.3-1.2 5.1 9.2S-1.2 34.7 9.2 42.9l592 464c10.4 8.2 25.5 6.3 33.7-4.1s6.3-25.5-4.1-33.7L525.6 386.7c39.6-40.6 66.4-86.1 79.9-118.4c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C465.5 68.8 400.8 32 320 32c-68.2 0-125 26.3-169.3 60.8L38.8 5.1zM223.1 149.5C248.6 126.2 282.7 112 320 112c79.5 0 144 64.5 144 144c0 24.9-6.3 48.3-17.4 68.7L408 294.5c5.2-11.8 8-24.8 8-38.5c0-53-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6c0 10.2-2.4 19.8-6.6 28.3l-90.3-70.8zm223.1 298L373 389.9c-16.4 6.5-34.3 10.1-53 10.1c-79.5 0-144-64.5-144-144c0-6.9 .5-13.6 1.4-20.2L83.1 161.5C60.3 191.2 44 220.8 34.5 243.7c-3.3 7.9-3.3 16.7 0 24.6c14.9 35.7 46.2 87.7 93 131.1C174.5 443.2 239.2 480 320 480c47.8 0 89.9-12.9 126.2-32.5z"/></svg></span></template>
        <template id=fa-copy><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M502.6 70.63l-61.25-61.25C435.4 3.371 427.2 0 418.7 0H255.1c-35.35 0-64 28.66-64 64l.0195 256C192 355.4 220.7 384 256 384h192c35.2 0 64-28.8 64-64V93.25C512 84.77 508.6 76.63 502.6 70.63zM464 320c0 8.836-7.164 16-16 16H255.1c-8.838 0-16-7.164-16-16L239.1 64.13c0-8.836 7.164-16 16-16h128L384 96c0 17.67 14.33 32 32 32h47.1V320zM272 448c0 8.836-7.164 16-16 16H63.1c-8.838 0-16-7.164-16-16L47.98 192.1c0-8.836 7.164-16 16-16H160V128H63.99c-35.35 0-64 28.65-64 64l.0098 256C.002 483.3 28.66 512 64 512h192c35.2 0 64-28.8 64-64v-32h-47.1L272 448z"/></svg></span></template>
        <template id=fa-play><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 384 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M73 39c-14.8-9.1-33.4-9.4-48.5-.9S0 62.6 0 80V432c0 17.4 9.4 33.4 24.5 41.9s33.7 8.1 48.5-.9L361 297c14.3-8.7 23-24.2 23-41s-8.7-32.2-23-41L73 39z"/></svg></span></template>
        <template id=fa-clock-rotate-left><span class=fa-svg><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc. --><path d="M75 75L41 41C25.9 25.9 0 36.6 0 57.9V168c0 13.3 10.7 24 24 24H134.1c21.4 0 32.1-25.9 17-41l-30.8-30.8C155 85.5 203 64 256 64c106 0 192 86 192 192s-86 192-192 192c-40.8 0-78.6-12.7-109.7-34.4c-14.5-10.1-34.4-6.6-44.6 7.9s-6.6 34.4 7.9 44.6C151.2 495 201.7 512 256 512c141.4 0 256-114.6 256-256S397.4 0 256 0C185.3 0 121.3 28.7 75 75zm181 53c-13.3 0-24 10.7-24 24V256c0 6.4 2.5 12.5 7 17l72 72c9.4 9.4 24.6 9.4 33.9 0s9.4-24.6 0-33.9l-65-65V152c0-13.3-10.7-24-24-24z"/></svg></span></template>



        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr-ef4e11c1.min.js"></script>
        <script src="mark-09e88c2c.min.js"></script>
        <script src="searcher-c2a407aa.js"></script>

        <script src="clipboard-1626706a.min.js"></script>
        <script src="highlight-abc7f01d.js"></script>
        <script src="book-a0b12cfe.js"></script>

        <!-- Custom JS scripts -->
        <script src="src/js/custom-links-620ec1bd.js"></script>



    </div>
    </body>
</html>
